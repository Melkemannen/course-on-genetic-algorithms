{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Genetic algorithm for neuroevolution** \n",
    "\n",
    "This notebook aims to find a solution to flappy bird by using a simple genetic algorithm to conduct a large search to fit a neural network. The algorithm is based on genomes consisting of a bitstring, mapping the bits to a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flappy-bird-gym in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: gym~=0.18.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flappy-bird-gym) (0.18.3)\n",
      "Requirement already satisfied: numpy~=1.19.5 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flappy-bird-gym) (1.19.5)\n",
      "Requirement already satisfied: pygame~=2.0.1 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flappy-bird-gym) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym~=0.18.0->flappy-bird-gym) (1.10.1)\n",
      "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym~=0.18.0->flappy-bird-gym) (1.5.15)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym~=0.18.0->flappy-bird-gym) (8.2.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym~=0.18.0->flappy-bird-gym) (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%pip install flappy-bird-gym\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import flappy_bird_gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a structure organism in order to keep track of the chromosome and the fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Organism:\n",
    "    def __init__(self, chromosome, fitness):\n",
    "        self.chromosome = \"\"\n",
    "        self.fitness = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains functions for converting the chromosome into a neural network, as well as useful functions like forward pass in order to let the creatures make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL!\n",
    "\n",
    "def bitstring_to_floats(bitstring, bits_per_value=10, min_val=-2, max_val=2):\n",
    "    \"\"\"Converts a bitstring into an array of float values while ensuring full extraction.\"\"\"\n",
    "    num_values = len(bitstring) // bits_per_value  # Ensure full number of weights\n",
    "    if num_values == 0:\n",
    "        raise ValueError(\"Bitstring too short for any weights!\")\n",
    "\n",
    "    floats = []\n",
    "    for i in range(num_values):\n",
    "        binary_segment = bitstring[i * bits_per_value:(i + 1) * bits_per_value]\n",
    "        decimal_value = int(binary_segment, 2)  # Convert binary to decimal\n",
    "        scaled_value = min_val + (max_val - min_val) * (decimal_value / (2**bits_per_value - 1))  # Normalize to [-2,2]\n",
    "        floats.append(scaled_value)\n",
    "\n",
    "    return np.array(floats)\n",
    "\n",
    "\n",
    "def decode_architecture(bitstring, bits_per_weight=10, input_size=2, output_size=1):\n",
    "    \"\"\"Extracts NN structure (neurons) and weights from a bitstring\"\"\"\n",
    "    hidden_neurons = int(bitstring[:4], 2) + 1  # Allow 1-16 hidden neurons\n",
    "    weights = bitstring_to_floats(bitstring[4:], bits_per_value=bits_per_weight)\n",
    "\n",
    "    # Compute expected number of weights\n",
    "    required_params = (input_size * hidden_neurons) + hidden_neurons + (hidden_neurons * output_size) + output_size\n",
    "\n",
    "    if len(weights) < required_params:\n",
    "        raise ValueError(f\"Decoded weights ({len(weights)}) are fewer than expected ({required_params}). \"\n",
    "                         f\"Ensure bitstring is at least {required_params * bits_per_weight} bits long!\")\n",
    "\n",
    "    return hidden_neurons, weights\n",
    "\n",
    "\n",
    "def construct_nn(bitstring, input_size=2, output_size=1):\n",
    "    \"\"\"Constructs a simple 1-layer NN from a bitstring with dynamic hidden neurons\"\"\"\n",
    "    hidden_neurons, params = decode_architecture(bitstring, input_size=input_size, output_size=output_size)\n",
    "\n",
    "    # Compute parameter indices\n",
    "    w1_end = input_size * hidden_neurons\n",
    "    b1_end = w1_end + hidden_neurons\n",
    "    w2_end = b1_end + (hidden_neurons * output_size)\n",
    "\n",
    "    # Debugging: Print out parameter sizes\n",
    "    # print(f\"Params Length: {len(params)} | Expected: {w2_end + output_size}\")\n",
    "    # print(f\"Hidden Neurons: {hidden_neurons}, Input Size: {input_size}, Output Size: {output_size}\")\n",
    "    # print(f\"w1: (0:{w1_end}), b1: ({w1_end}:{b1_end}), w2: ({b1_end}:{w2_end}), b2: ({w2_end}:{w2_end + output_size})\")\n",
    "\n",
    "    # Extract weights and biases\n",
    "    w1 = params[:w1_end].reshape(input_size, hidden_neurons)  # (input_size, hidden_neurons)\n",
    "    b1 = params[w1_end:b1_end]  # (hidden_neurons,)\n",
    "    w2 = params[b1_end:w2_end].reshape(hidden_neurons, output_size)  # (hidden_neurons, output_size)\n",
    "    b2 = params[w2_end:w2_end + output_size]  # (output_size,)\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass(X, w1, b1, w2, b2):\n",
    "    \"\"\"Performs forward propagation through the neural network\"\"\"\n",
    "    hidden = np.tanh(np.dot(X, w1) + b1)  # (batch, hidden)\n",
    "    output = np.tanh(np.dot(hidden, w2) + b2)  # (batch, 1)\n",
    "\n",
    "    return output\n",
    "\n",
    "def required_bitstring_length(hidden_neurons=16, input_size=2, output_size=1, bits_per_weight=10):\n",
    "    \"\"\"Compute the required bitstring length for encoding all NN parameters.\"\"\"\n",
    "    required_params = (input_size * hidden_neurons) + hidden_neurons + (hidden_neurons * output_size) + output_size\n",
    "    return required_params * bits_per_weight  # Convert to bitstring length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load best genome of a run\n",
    "def save_best_genome(genome, filename):\n",
    "    \"\"\"Saves the best genome to a file\"\"\"\n",
    "    \n",
    "    with open (filename, 'w') as f:\n",
    "        f.write(genome)\n",
    "        \n",
    "def load_best_genome(filename):\n",
    "    \"\"\"Loads the best genome from a file\"\"\"\n",
    "    \n",
    "    with open (filename, 'r') as f:\n",
    "        genome = f.read()\n",
    "        \n",
    "    return genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize population**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(pop_size, genome_length):\n",
    "    \"\"\"Initializes a population of genomes\"\"\"\n",
    "    return[\"\".join(np.random.choice([\"0\", \"1\"], genome_length)) for _ in range(pop_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitness Function**\n",
    "The fitness of a genome is calculated in a fitness function. This often the only domain centric part of a genetic algorithm, meaning that the neural network will be trained based on what kind of environment the fitness function uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "\n",
    "def evaluate_fitness(chromosome):\n",
    "    \"\"\"Evaluates a chromosome based on its fitness.\"\"\"\n",
    "    hidden_neurons, params = decode_architecture(chromosome)\n",
    "    w1, b1, w2, b2 = construct_nn(chromosome)\n",
    "\n",
    "    # Run the game\n",
    "    obs, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            X = np.array(obs).reshape(1, 2)   \n",
    "        except:\n",
    "            X = np.array([0.1,1.0]).reshape(1, 2) # the first observation is not in the correct shape\n",
    "\n",
    "        # Forward pass through the NN\n",
    "        output = forward_pass(X, w1, b1, w2, b2)\n",
    "        \n",
    "        # TODO: play around with the threshold and see if you can get a better model\n",
    "        action = 1 if output > 0.7 else 0\n",
    "\n",
    "        # Take the action\n",
    "        obs, reward, terminated, info = env.step(action)\n",
    "        total_reward += reward - action * 7\n",
    "        \n",
    "        # Check if the game is over\n",
    "        if terminated:\n",
    "            break\n",
    "        \n",
    "    # clamp reward to be at least 0.000001\n",
    "    return max(total_reward, 0.000001) +  + int(info['score'])*1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crossover**\n",
    "The crossover function decides how different genomes should mate in order to produce offspring. \n",
    "The gene representation is in the form of a bitstring.\n",
    "\n",
    "**Task** \n",
    "Define your own set of crossover functions by implementing different policies to combine the bitstirng of two parents. All genomes are the same length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_crossover(parent1, parent2):\n",
    "    \"\"\"Uniform crossover for binary genomes\"\"\"\n",
    "    mask = np.random.randint(2, size=len(parent1))  # Random bit mask\n",
    "    child1 = \"\".join([parent1[i] if mask[i] else parent2[i] for i in range(len(parent1))])\n",
    "    child2 = \"\".join([parent2[i] if mask[i] else parent1[i] for i in range(len(parent1))])\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "def single_point_crossover(parent1, parent2, crossover_rate=0.9):\n",
    "    \"\"\"Single-point crossover for binary genomes\"\"\"\n",
    "    if np.random.rand() > crossover_rate:\n",
    "        return parent1, parent2\n",
    "    split_point = np.random.randint(1, len(parent1) - 1)  # Random split point\n",
    "    child1 = parent1[:split_point] + parent2[split_point:]\n",
    "    child2 = parent2[:split_point] + parent1[split_point:]\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, crossover_rate=0.9):\n",
    "    random_number = np.random.rand()\n",
    "    if random_number < 0.5:\n",
    "        return single_point_crossover(parent1, parent2, crossover_rate)\n",
    "    else:\n",
    "        return uniform_crossover(parent1, parent2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_flip_mutation(bitstring, mutation_rate=0.01):\n",
    "    \"\"\"Flips random bits with given probability\"\"\"\n",
    "    return \"\".join([bit if np.random.rand() > mutation_rate else str(1 - int(bit)) for bit in bitstring])\n",
    "\n",
    "\n",
    "def adaptive_mutate(chromosome, generation, max_generations, mutation_rate=0.01, diversity_factor=1):\n",
    "    \"\"\"Adapts mutation rate based on population diversity.\"\"\"\n",
    "    adjusted_mutation_rate = mutation_rate * (1 - (generation / max_generations)) * diversity_factor\n",
    "\n",
    "    chromosome_list = list(chromosome)  # Convert to mutable list\n",
    "    for i in range(len(chromosome_list)):\n",
    "        if np.random.rand() < adjusted_mutation_rate:\n",
    "            chromosome_list[i] = '1' if chromosome_list[i] == '0' else '0'  # Flip bit\n",
    "\n",
    "    return \"\".join(chromosome_list)  # Convert back to string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_crowding(parent1, parent2, child1, child2, fitness_function):\n",
    "    \"\"\"Ensures offspring compete with similar parents.\"\"\"\n",
    "    f_p1 = fitness_function(parent1)\n",
    "    f_p2 = fitness_function(parent2)\n",
    "    f_c1 = fitness_function(child1)\n",
    "    f_c2 = fitness_function(child2)\n",
    "\n",
    "    new1 = child1 if f_c1 > f_p1 else parent1\n",
    "    new2 = child2 if f_c2 > f_p2 else parent2\n",
    "\n",
    "    return new1, new2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(bitstring1, bitstring2):\n",
    "    \"\"\"Calculates Hamming distance between two bitstrings.\"\"\"\n",
    "    return sum(b1 != b2 for b1, b2 in zip(bitstring1, bitstring2))\n",
    "\n",
    "\n",
    "def fitness_sharing(population, fitnesses, sigma_share=10, alpha=2):\n",
    "    \"\"\"Applies fitness sharing to promote diversity.\"\"\"\n",
    "    shared_fitnesses = np.zeros(len(fitnesses))\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        niche_count = 0\n",
    "        for j in range(len(population)):\n",
    "            if i != j:\n",
    "                distance = hamming_distance(population[i], population[j])\n",
    "                if distance < sigma_share:  # If genomes are similar\n",
    "                    niche_count += (1 - (distance / sigma_share)) ** alpha\n",
    "\n",
    "        shared_fitnesses[i] = fitnesses[i] / (1 + niche_count)  # Penalize common solutions\n",
    "\n",
    "    return shared_fitnesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, fitnesses, tournament_size=10):\n",
    "    \"\"\"Select best genome from a random subset\"\"\"\n",
    "    indices = np.random.choice(len(population), tournament_size, replace=False)\n",
    "    best_index = indices[np.argmax([fitnesses[i] for i in indices])]\n",
    "    return population[best_index]\n",
    "\n",
    "\n",
    "def roulette_wheel_selection(population, fitnesses):\n",
    "    \"\"\"Selects individuals using fitness proportionate selection.\"\"\"\n",
    "    total_fitness = np.sum(fitnesses)\n",
    "    probabilities = fitnesses / total_fitness\n",
    "    return population[np.random.choice(len(population), p=probabilities)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(pop_size, genome_length, generations):\n",
    "    \"\"\"Runs a genetic algorithm to evolve a neural network\"\"\"\n",
    "    # Initialize population (random bitstrings)\n",
    "    population = initial_population(pop_size, genome_length)\n",
    "    max_generation = population\n",
    "\n",
    "    for gen in range(generations):\n",
    "        fitnesses = np.array([evaluate_fitness(ind) for ind in population])\n",
    "        fitnesses = fitness_sharing(population, fitnesses)  # Apply fitness sharing\n",
    "        \n",
    "        new_population = []\n",
    "        # TODO: Elitism saves the top 20 % of the population. Play around with this number and see if you can get a better model\n",
    "        # keep the 20% best genomes\n",
    "        new_population.extend([population[i] for i in np.argsort(fitnesses)[-int(pop_size * 0.2):]])\n",
    "        while len(new_population) < pop_size:\n",
    "            # Select parents\n",
    "            #parent1, parent2 = tournament_selection(population, fitnesses), tournament_selection(population, fitnesses)\n",
    "            parent1 = roulette_wheel_selection(population, fitnesses)\n",
    "            parent2 = roulette_wheel_selection(population, fitnesses)\n",
    "            # Crossover & Mutation\n",
    "            #child1, child2 = uniform_crossover(parent1, parent2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            child1, child2 = bit_flip_mutation(child1), bit_flip_mutation(child2)\n",
    "            #diversity_factor = 1 + (np.mean(fitness_sharing(population, fitnesses)) * 0.5)  # Scale mutation if diversity is low\n",
    "            #child1 = adaptive_mutate(child1, gen, generations, diversity_factor=diversity_factor)\n",
    "            #child2 = adaptive_mutate(child2, gen, generations, diversity_factor=diversity_factor)\n",
    "            #child1, child2 = deterministic_crowding(parent1, parent2, child1, child2, evaluate_fitness)\n",
    "            \n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        # Replace population (keep best elite)\n",
    "        best_idx = np.argmax(fitnesses)\n",
    "        best_genome = population[best_idx]\n",
    "        population = new_population[:pop_size]\n",
    "        population[0] = best_genome  # Elitism\n",
    "        if population[np.argmax(fitnesses)] == best_genome:\n",
    "            max_generation = population.copy()\n",
    "        \n",
    "        print(f\"Generation {gen + 1}: Best Fitness = {max(fitnesses):.6f} avg fitness = {np.mean(fitnesses):.6f}\")\n",
    "       \n",
    "    \n",
    "    best_genome = max_generation[np.argmax(fitnesses)]\n",
    "    print(f\"Best genome: {best_genome}\")\n",
    "    return best_genome  # Return best genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network successfully built with shapes:\n",
      "w1: (2, 2), b1: (2,), w2: (2, 1), b2: (1,)\n",
      "Required bitstring length: 660 bits\n",
      "Generation 1: Best Fitness = 59.000000 avg fitness = 17.580000\n",
      "Generation 2: Best Fitness = 1056.000000 avg fitness = 46.641177\n",
      "Generation 3: Best Fitness = 27293.000000 avg fitness = 603.306823\n",
      "Generation 4: Best Fitness = 129318.343195 avg fitness = 7688.522419\n",
      "Generation 5: Best Fitness = 126616.000000 avg fitness = 16120.467538\n",
      "Generation 6: Best Fitness = 338737.000000 avg fitness = 29399.305178\n",
      "Generation 7: Best Fitness = 393030.508475 avg fitness = 26659.304376\n",
      "Generation 8: Best Fitness = 117029.310345 avg fitness = 10932.290593\n",
      "Generation 9: Best Fitness = 247136.000000 avg fitness = 16736.225599\n",
      "Generation 10: Best Fitness = 433079.000000 avg fitness = 30593.454297\n",
      "Generation 11: Best Fitness = 194584.000000 avg fitness = 19833.251681\n",
      "Generation 12: Best Fitness = 406220.000000 avg fitness = 23256.816692\n",
      "Generation 13: Best Fitness = 118271.000000 avg fitness = 12807.725836\n",
      "Generation 14: Best Fitness = 298148.623853 avg fitness = 19373.229817\n",
      "Generation 15: Best Fitness = 238063.302752 avg fitness = 27591.600775\n",
      "Generation 16: Best Fitness = 229842.000000 avg fitness = 19625.475879\n",
      "Generation 17: Best Fitness = 179469.000000 avg fitness = 19739.974681\n",
      "Generation 18: Best Fitness = 272388.000000 avg fitness = 23695.086982\n",
      "Generation 19: Best Fitness = 169379.000000 avg fitness = 22542.566487\n",
      "Generation 20: Best Fitness = 715828.000000 avg fitness = 36485.883520\n",
      "Generation 21: Best Fitness = 145900.000000 avg fitness = 26026.499418\n",
      "Generation 22: Best Fitness = 191577.000000 avg fitness = 23850.759750\n",
      "Generation 23: Best Fitness = 121509.000000 avg fitness = 16025.915084\n",
      "Generation 24: Best Fitness = 291425.000000 avg fitness = 29073.235149\n",
      "Generation 25: Best Fitness = 344952.000000 avg fitness = 23784.262718\n",
      "Generation 26: Best Fitness = 179517.000000 avg fitness = 22221.043428\n",
      "Generation 27: Best Fitness = 275388.000000 avg fitness = 41120.738329\n",
      "Generation 28: Best Fitness = 124308.800000 avg fitness = 20190.996041\n",
      "Generation 29: Best Fitness = 161174.000000 avg fitness = 17163.385568\n",
      "Generation 30: Best Fitness = 172288.000000 avg fitness = 21167.640000\n",
      "Generation 31: Best Fitness = 252523.000000 avg fitness = 27603.449663\n",
      "Generation 32: Best Fitness = 132579.000000 avg fitness = 21467.417952\n",
      "Generation 33: Best Fitness = 153034.615385 avg fitness = 20165.215942\n",
      "Generation 34: Best Fitness = 193665.000000 avg fitness = 24538.539561\n",
      "Generation 35: Best Fitness = 401932.000000 avg fitness = 24775.901416\n",
      "Generation 36: Best Fitness = 225834.000000 avg fitness = 23692.189631\n",
      "Generation 37: Best Fitness = 592576.000000 avg fitness = 33821.432153\n",
      "Generation 38: Best Fitness = 141106.000000 avg fitness = 14312.721264\n",
      "Generation 39: Best Fitness = 290844.000000 avg fitness = 28676.766923\n",
      "Generation 40: Best Fitness = 158804.417671 avg fitness = 16780.773188\n",
      "Generation 41: Best Fitness = 303638.000000 avg fitness = 33840.789871\n",
      "Generation 42: Best Fitness = 191647.000000 avg fitness = 28633.770090\n",
      "Generation 43: Best Fitness = 408000.000000 avg fitness = 26182.783452\n",
      "Generation 44: Best Fitness = 291581.000000 avg fitness = 27498.404644\n",
      "Generation 45: Best Fitness = 221420.000000 avg fitness = 25775.744504\n",
      "Generation 46: Best Fitness = 189471.559633 avg fitness = 22164.830207\n",
      "Generation 47: Best Fitness = 222798.000000 avg fitness = 27590.484487\n",
      "Generation 48: Best Fitness = 166745.192308 avg fitness = 9488.260513\n",
      "Generation 49: Best Fitness = 245720.000000 avg fitness = 13572.468220\n",
      "Generation 50: Best Fitness = 193982.000000 avg fitness = 18925.724006\n",
      "Best genome: 100111100000100100100001000001111101011111011001111011111010010101011001110100010010010000100110011101000000010010111111011010001101001111011110010001001011001010011100101001001001101011010101000010101010011001001100100000001001000101111000110000000010100101000100000011111101101110000001110011101000111111111011001111110100101101010000100101110000001000011001000001001111001101000100001001001110001100111001110000101010100101101011101110001011000100110100111111101010101100001000000010011110000100101010000110100000101100010111011001100101001110010100001010011111010011100110100000111000001011110000110110101001000101100100111111100111111111111001111001000011\n"
     ]
    }
   ],
   "source": [
    "random_bitstring = \"\".join(np.random.choice([\"0\", \"1\"], required_bitstring_length(hidden_neurons=11)))\n",
    "\n",
    "try:\n",
    "    w1, b1, w2, b2 = construct_nn(random_bitstring)\n",
    "    print(\"Neural Network successfully built with shapes:\")\n",
    "    print(f\"w1: {w1.shape}, b1: {b1.shape}, w2: {w2.shape}, b2: {b2.shape}\")\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "hidden_neurons = 16  # Max number of hidden neurons\n",
    "bits_per_weight = 10\n",
    "\n",
    "required_length = required_bitstring_length(hidden_neurons, input_size, output_size, bits_per_weight) +10\n",
    "\n",
    "print(f\"Required bitstring length: {required_length} bits\")  # Debugging\n",
    "\n",
    "best_genome = genetic_algorithm(\n",
    "    pop_size=50, \n",
    "    genome_length=required_length,  # 16 parameters Ã— 8 bits\n",
    "    generations=50\n",
    "    \n",
    ")\n",
    "save_best_genome(best_genome, \"best_genome.txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 181}\n",
      "{'score': 7}\n",
      "{'score': 90}\n",
      "{'score': 205}\n",
      "{'score': 42}\n",
      "{'score': 112}\n",
      "{'score': 476}\n",
      "{'score': 52}\n",
      "{'score': 173}\n",
      "{'score': 52}\n",
      "{'score': 126}\n",
      "{'score': 13}\n",
      "{'score': 13}\n",
      "{'score': 135}\n",
      "{'score': 463}\n",
      "{'score': 129}\n",
      "{'score': 85}\n",
      "{'score': 39}\n",
      "{'score': 11}\n",
      "{'score': 75}\n",
      "{'score': 123}\n",
      "{'score': 280}\n",
      "{'score': 4}\n",
      "{'score': 53}\n",
      "{'score': 143}\n",
      "{'score': 76}\n",
      "{'score': 104}\n",
      "{'score': 3}\n",
      "{'score': 21}\n",
      "{'score': 204}\n",
      "{'score': 88}\n",
      "{'score': 93}\n",
      "{'score': 41}\n",
      "{'score': 22}\n",
      "{'score': 60}\n",
      "{'score': 56}\n",
      "{'score': 55}\n",
      "{'score': 161}\n",
      "{'score': 128}\n",
      "{'score': 206}\n",
      "{'score': 131}\n",
      "{'score': 22}\n",
      "{'score': 8}\n",
      "{'score': 69}\n",
      "{'score': 160}\n",
      "{'score': 123}\n",
      "{'score': 29}\n",
      "{'score': 3}\n",
      "{'score': 69}\n",
      "{'score': 24}\n",
      "{'score': 28}\n",
      "{'score': 22}\n",
      "{'score': 357}\n",
      "{'score': 77}\n",
      "{'score': 186}\n",
      "{'score': 126}\n",
      "{'score': 93}\n",
      "{'score': 166}\n",
      "{'score': 5}\n",
      "{'score': 9}\n",
      "{'score': 235}\n",
      "{'score': 69}\n",
      "{'score': 21}\n",
      "{'score': 155}\n",
      "{'score': 3}\n",
      "{'score': 64}\n",
      "{'score': 47}\n",
      "{'score': 195}\n",
      "{'score': 3}\n",
      "{'score': 31}\n",
      "{'score': 291}\n",
      "{'score': 37}\n",
      "{'score': 403}\n",
      "{'score': 103}\n",
      "{'score': 136}\n",
      "{'score': 78}\n",
      "{'score': 13}\n",
      "{'score': 28}\n",
      "{'score': 2}\n",
      "{'score': 53}\n",
      "{'score': 65}\n",
      "{'score': 37}\n",
      "{'score': 113}\n",
      "{'score': 225}\n",
      "{'score': 152}\n",
      "{'score': 11}\n",
      "{'score': 167}\n",
      "{'score': 15}\n",
      "{'score': 7}\n",
      "{'score': 70}\n",
      "{'score': 116}\n",
      "{'score': 189}\n",
      "{'score': 125}\n",
      "{'score': 327}\n",
      "{'score': 16}\n",
      "{'score': 124}\n",
      "{'score': 294}\n",
      "{'score': 71}\n",
      "{'score': 7}\n",
      "{'score': 13}\n",
      "best score:  476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "\n",
    "num_inputs = 2 # The envirement has 12 observations for each frame\n",
    "num_outputs = 1 # The envirement has 1 action space (flap or do nothing)\n",
    "    \n",
    "best_genome = load_best_genome(\"best_genome_score_275.txt\")\n",
    "w1, b1, w2, b2 = construct_nn(best_genome, input_size=num_inputs, output_size=num_outputs)\n",
    "total_reward = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(100):\n",
    "    obs, _ = env.reset()\n",
    "    while True:\n",
    "        try:\n",
    "            X = np.array(obs).reshape(1, 2)\n",
    "        except:\n",
    "            X = np.array([0.1,1.0]).reshape(1, 2)\n",
    "        # Forward pass through the NN\n",
    "        output = forward_pass(X, w1, b1, w2, b2)\n",
    "        action = 1 if output > 0.7 else 0\n",
    "        obs, reward, terminated, info = env.step(action)\n",
    "        \n",
    "        if terminated:\n",
    "            break\n",
    "    print(info)\n",
    "    if info['score'] > best_score:\n",
    "        best_score = info['score']\n",
    "    \n",
    "print(\"best score: \", best_score)   \n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 184}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "env = flappy_bird_gym.make(\"FlappyBird-v0\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# Neural network parameters:\n",
    "# ===============================================================\n",
    "num_inputs = 2 # The envirement has 12 observations for each frame\n",
    "num_outputs = 1 # The envirement has 1 action space (flap or do nothing)\n",
    "    \n",
    "#best_genome = load_best_genome(\"best_genome.txt\")\n",
    "w1, b1, w2, b2 = construct_nn(best_genome, input_size=num_inputs, output_size=num_outputs)\n",
    "obs, _ = env.reset()\n",
    "total_reward = 0\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        X = np.array(obs).reshape(1, 2)\n",
    "    except:\n",
    "        X = np.array([0.1,1.0]).reshape(1, 2)\n",
    "\n",
    "    # Forward pass through the NN\n",
    "    output = forward_pass(X, w1, b1, w2, b2)\n",
    "    action = 1 if output > 0.7 else 0\n",
    "    obs, reward, terminated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    env.render()\n",
    "    time.sleep(1 / 30)\n",
    "    \n",
    "    if terminated:\n",
    "        break\n",
    "print(info)\n",
    "    \n",
    "  \n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pygame\n",
    "# import numpy as np\n",
    "\n",
    "# def draw_neural_network(chromosome, screen_size=(800, 600)):\n",
    "#     \"\"\"\n",
    "#     Draws a neural network based on the given chromosome using Pygame.\n",
    "\n",
    "#     Parameters:\n",
    "#     - chromosome: Bitstring representing the neural network structure.\n",
    "#     - screen_size: Tuple (width, height) for pygame window.\n",
    "#     \"\"\"\n",
    "#     # Decode the architecture and construct the neural network\n",
    "#     hidden_neurons, params = decode_architecture(chromosome)\n",
    "#     w1, b1, w2, b2 = construct_nn(chromosome)\n",
    "\n",
    "#     # Ensure hidden_neurons is a list\n",
    "#     input_neurons = 2  # From the Flappy Bird environment\n",
    "#     output_neurons = 1  # Single output neuron\n",
    "#     layers = [input_neurons] + ([hidden_neurons] if isinstance(hidden_neurons, int) else hidden_neurons) + [output_neurons]\n",
    "\n",
    "#     pygame.init()\n",
    "#     screen = pygame.display.set_mode(screen_size)\n",
    "#     pygame.display.set_caption(\"Neural Network Visualization\")\n",
    "\n",
    "#     # Colors\n",
    "#     WHITE = (255, 255, 255)\n",
    "#     BLACK = (0, 0, 0)\n",
    "#     BLUE = (50, 150, 255)\n",
    "#     GREEN = (100, 255, 100)\n",
    "#     RED = (255, 50, 50)\n",
    "\n",
    "#     screen.fill(WHITE)\n",
    "\n",
    "#     # Define spacing\n",
    "#     width, height = screen_size\n",
    "#     layer_spacing = width // (len(layers) + 1)  # Space between layers\n",
    "#     node_radius = 20  # Neuron size\n",
    "#     y_padding = 80  # Padding from top/bottom\n",
    "\n",
    "#     # Compute node positions\n",
    "#     node_positions = []  # List of lists for neuron positions\n",
    "\n",
    "#     for i, neurons in enumerate(layers):\n",
    "#         x = (i + 1) * layer_spacing\n",
    "#         y_spacing = (height - 2 * y_padding) // (neurons - 1) if neurons > 1 else 200\n",
    "\n",
    "#         layer_nodes = []\n",
    "#         for j in range(neurons):\n",
    "#             y = y_padding + j * y_spacing\n",
    "#             layer_nodes.append((x, y))\n",
    "\n",
    "#         node_positions.append(layer_nodes)\n",
    "\n",
    "#     # Draw connections (edges) with weight intensity\n",
    "#     for i in range(len(layers) - 1):\n",
    "#         weight_matrix = w1 if i == 0 else w2  # Use w1 for input-hidden, w2 for hidden-output\n",
    "#         layer1_nodes = node_positions[i]\n",
    "#         layer2_nodes = node_positions[i + 1]\n",
    "\n",
    "#         for j, node1 in enumerate(layer1_nodes):  # Nodes in layer i\n",
    "#             for k, node2 in enumerate(layer2_nodes):  # Nodes in layer i+1\n",
    "#                 try:\n",
    "#                     weight = weight_matrix[k, j]  # Extract weight\n",
    "#                     color = GREEN if weight > 0 else RED  # Green for positive, red for negative\n",
    "#                     thickness = int(abs(weight) * 5) + 1  # Scale thickness\n",
    "#                 except:\n",
    "#                     pass\n",
    "                    \n",
    "#                 pygame.draw.line(screen, color, node1, node2, thickness)\n",
    "\n",
    "#     # Draw nodes (neurons)\n",
    "#     for layer in node_positions:\n",
    "#         for node in layer:\n",
    "            \n",
    "#             pygame.draw.circle(screen, BLUE, node, node_radius)\n",
    "#             pygame.draw.circle(screen, BLACK, node, node_radius, 2)  # Outline\n",
    "\n",
    "#     # Display network\n",
    "#     pygame.display.flip()\n",
    "\n",
    "#     # Wait until user closes the window\n",
    "#     running = True\n",
    "#     while running:\n",
    "#         for event in pygame.event.get():\n",
    "#             if event.type == pygame.QUIT:\n",
    "#                 running = False\n",
    "\n",
    "#     pygame.quit()\n",
    "\n",
    "\n",
    "\n",
    "# draw_neural_network(load_best_genome(\"best_genome.txt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
